{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from math import cos, sin, atan\n",
    "\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedConfig():\n",
    "    def __init__(self, learning_ratio = 0.01, iteration_limit = 1000, err_max = 0.1, graphic_resolution = 50, interval_show = 2):\n",
    "        self.__learning_ratio = learning_ratio\n",
    "        self.__iteration_limit = iteration_limit\n",
    "        self.__err_max = err_max\n",
    "        self.__graphic_resolution = graphic_resolution\n",
    "        self.__interval_show = interval_show\n",
    "        \n",
    "    def get_learning_ratio(self):\n",
    "        return self.__learning_ratio\n",
    "    \n",
    "    def get_iteration_limit(self):\n",
    "        return self.__iteration_limit\n",
    "    \n",
    "    def get_err_max(self):\n",
    "        return self.__err_max\n",
    "    \n",
    "    def get_graphic_resolution(self):\n",
    "        return self.__graphic_resolution\n",
    "    \n",
    "    def get_interval_show(self):\n",
    "        return self.__interval_show\n",
    "    \n",
    "    \n",
    "    \n",
    "    def set_learning_ratio(self, _learning_ratio):\n",
    "        try:\n",
    "            self.__learning_ratio = _learning_ratio\n",
    "        except:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def set_iteration_limit(self, _iteration_limit):\n",
    "        try:\n",
    "            self.__iteration_limit = _iteration_limit\n",
    "        except:\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    def set_err_max(self, _err_max):\n",
    "        try:\n",
    "            self.__err_max = _err_max\n",
    "        except:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def set_graphic_resolution(self, _graphic_resolution):\n",
    "        try:\n",
    "            self.__graphic_resolution = _graphic_resolution\n",
    "        except:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def set_interval_show(self, _interval_show):\n",
    "        try:\n",
    "            self.__interval_show = _interval_show\n",
    "        except:\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Manager Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileManager():\n",
    "    \n",
    "    def __init__(self, project_path):\n",
    "        \n",
    "        self.project_name = project_path.split(\"/\")[-1]\n",
    "        self.project_path = project_path.replace(self.project_name, \"\")\n",
    "        self.dataset_path = \"\"\n",
    "        self.delimiter_format = \"\"\n",
    "        \n",
    "        \n",
    "    def count_in_out(self):\n",
    "        \n",
    "        first_row = np.loadtxt(self.dataset_path, delimiter = self.delimiter_format, dtype=str, max_rows=1)\n",
    "        \n",
    "        n_XY = [0,0]\n",
    "        \n",
    "        for l, _data in enumerate(first_row):\n",
    "            if \"X\" in str.upper(first_row[l]):\n",
    "                n_XY[0] += 1 \n",
    "            if \"Y\" in str.upper(first_row[l]):\n",
    "                n_XY[1] += 1 \n",
    "                \n",
    "        return n_XY\n",
    "    \n",
    "    \n",
    "    # Import data\n",
    "    def import_dataset(self, cols = []):\n",
    "        data = np.loadtxt(self.dataset_path, delimiter=self.delimiter_format, skiprows=1, usecols=cols, dtype=float)\n",
    "        return data\n",
    "    \n",
    "    def import_file(self, file_name = \"\"):\n",
    "        data = np.loadtxt(file_name, delimiter=self.delimiter_format, usecols=None, dtype=str)\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canvas for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Canvas(FigureCanvas):\n",
    "\n",
    "    def __init__(self, parent=None):\n",
    "        fig = Figure()\n",
    "        self.axes = fig.add_subplot(111)\n",
    "\n",
    "        self.compute_initial_figure()\n",
    "\n",
    "        FigureCanvas.__init__(self, fig)\n",
    "        self.setParent(parent)\n",
    "\n",
    "        FigureCanvas.setSizePolicy(self,\n",
    "                                   QSizePolicy.Expanding,\n",
    "                                   QSizePolicy.Expanding)\n",
    "        FigureCanvas.updateGeometry(self)\n",
    "\n",
    "    def compute_initial_figure(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: rustic graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphicNeuron():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def draw(self, neuron_radius):\n",
    "        circle = plt.Circle((self.x, self.y), radius=neuron_radius, fill=False)\n",
    "        plt.gca().add_patch(circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphicLayer():\n",
    "    def __init__(self, network, number_of_neurons, number_of_neurons_in_widest_layer):\n",
    "        self.vertical_distance_between_layers = 6\n",
    "        self.horizontal_distance_between_neurons = 2\n",
    "        self.neuron_radius = 0.5\n",
    "        self.number_of_neurons_in_widest_layer = number_of_neurons_in_widest_layer\n",
    "        self.previous_layer = self.__get_previous_layer(network)\n",
    "        self.y = self.__calculate_layer_y_position()\n",
    "        self.neurons = self.__intialise_neurons(number_of_neurons)\n",
    "\n",
    "    def __intialise_neurons(self, number_of_neurons):\n",
    "        neurons = []\n",
    "        x = self.__calculate_left_margin_so_layer_is_centered(number_of_neurons)\n",
    "        for iteration in range(number_of_neurons):\n",
    "            neuron = GraphicNeuron(x, self.y)\n",
    "            neurons.append(neuron)\n",
    "            x += self.horizontal_distance_between_neurons\n",
    "        return neurons\n",
    "\n",
    "    def __calculate_left_margin_so_layer_is_centered(self, number_of_neurons):\n",
    "        return self.horizontal_distance_between_neurons * (self.number_of_neurons_in_widest_layer - number_of_neurons) / 2\n",
    "\n",
    "    def __calculate_layer_y_position(self):\n",
    "        if self.previous_layer:\n",
    "            return self.previous_layer.y + self.vertical_distance_between_layers\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __get_previous_layer(self, network):\n",
    "        if len(network.layers) > 0:\n",
    "            return network.layers[-1]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __line_between_two_neurons(self, neuron1, neuron2):\n",
    "        angle = atan((neuron2.x - neuron1.x) / float(neuron2.y - neuron1.y))\n",
    "        x_adjustment = self.neuron_radius * sin(angle)\n",
    "        y_adjustment = self.neuron_radius * cos(angle)\n",
    "        line = plt.Line2D((neuron1.x - x_adjustment, neuron2.x + x_adjustment), (neuron1.y - y_adjustment, neuron2.y + y_adjustment))\n",
    "        plt.gca().add_line(line)\n",
    "\n",
    "    def draw(self, layerType=0):\n",
    "        for neuron in self.neurons:\n",
    "            neuron.draw( self.neuron_radius )\n",
    "            if self.previous_layer:\n",
    "                for previous_layer_neuron in self.previous_layer.neurons:\n",
    "                    self.__line_between_two_neurons(neuron, previous_layer_neuron)\n",
    "        # write Text\n",
    "        x_text = self.number_of_neurons_in_widest_layer * self.horizontal_distance_between_neurons\n",
    "        if layerType == 0:\n",
    "            plt.text(x_text, self.y, 'Capa de Entrada', fontsize = 12)\n",
    "        elif layerType == -1:\n",
    "            plt.text(x_text, self.y, 'Capa de Salida ', fontsize = 12)\n",
    "        else:\n",
    "            plt.text(x_text, self.y, 'Capa Oculta '+str(layerType), fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphicNeuralNetwork():\n",
    "    def __init__(self, number_of_neurons_in_widest_layer):\n",
    "        self.number_of_neurons_in_widest_layer = number_of_neurons_in_widest_layer\n",
    "        self.layers = []\n",
    "        self.layertype = 0\n",
    "\n",
    "    def add_layer(self, number_of_neurons ):\n",
    "        layer = GraphicLayer(self, number_of_neurons, self.number_of_neurons_in_widest_layer)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def draw(self):\n",
    "        plt.figure()\n",
    "        for i in range( len(self.layers) ):\n",
    "            layer = self.layers[i]\n",
    "            if i == len(self.layers)-1:\n",
    "                i = -1\n",
    "            layer.draw( i )\n",
    "        plt.axis('scaled')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, n_XY):\n",
    "        self.n_X = n_XY[0]\n",
    "        self.n_Y = n_XY[1]\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        \n",
    "        \n",
    "    def import_X_dataset(self, file_manager):\n",
    "        cols = []\n",
    "        \n",
    "        for i_x in range(0, self.n_X):\n",
    "            cols.append(i_x)\n",
    "        \n",
    "        self.X = file_manager.import_dataset(cols)\n",
    "        \n",
    "    def import_Y_dataset(self, file_manager):\n",
    "        cols = []\n",
    "        \n",
    "        for i_y in range(self.n_X, self.n_X + self.n_Y):\n",
    "            cols.append(i_y)\n",
    "            \n",
    "        self.Y = file_manager.import_dataset(cols)\n",
    "        self.fix_Y_axis()\n",
    "        \n",
    "    def fix_Y_axis(self):\n",
    "        self.Y = self.Y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure: neural layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural layer builder\n",
    "\n",
    "class NeuralLayer():\n",
    "    # The class is initialized receiving the parameters:\n",
    "    # n_conn: connections number, neurons of layer before\n",
    "    # n_neur: neurons number\n",
    "    # act_f: activation function\n",
    "    \n",
    "    def __init__ (self, n_connection, n_neuron, activation_function):\n",
    "        \n",
    "        self.activation_function = activation_function\n",
    "        self.W = np.random.rand(n_connection, n_neuron) * 2 - 1 \n",
    "        self.b = np.random.rand(1, n_neuron) * 2 - 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe83ec2e640>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ActivationFunction():\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.step = lambda x: x >= 0\n",
    "\n",
    "        self.sigm = (lambda x: 1 / (1 + np.exp(-x)), \n",
    "                     lambda x: (lambda value=self.sigm[0](x): value * (1 - value))()\n",
    "                    )\n",
    "\n",
    "        self.relu = (lambda x: np.maximum(0, x),\n",
    "                     lambda x: x > 0\n",
    "                    )\n",
    "\n",
    "        self.tanh = (lambda x: np.tanh(x),\n",
    "                     lambda x: 1.0 - (np.tanh(x) ** 2)\n",
    "                    )\n",
    "        \n",
    "        self.linear = (lambda x: x,\n",
    "                       lambda x: 1\n",
    "                      )\n",
    "        \n",
    "#         self.gauss = (lambda x: ,\n",
    "#                      lambda x: \n",
    "#                     )\n",
    "\n",
    "\n",
    "\n",
    "active = ActivationFunction()\n",
    "_x = np.linspace(-5,5,100)   # Variable que vaya de 5 a -5 y genera 100 valores\n",
    "plt.plot(_x,active.sigm[1](_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self, topology, activation_function, red_config, dataset):\n",
    "        \n",
    "        self.topology = topology\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.red_config = red_config\n",
    "        \n",
    "        self.cost_function = (lambda Yp, Yr: np.mean((Yp - Yr) ** 2),\n",
    "                              lambda Yp, Yr: (Yp - Yr)\n",
    "                             )\n",
    "        self.create_nn()\n",
    "\n",
    "    \n",
    "    def create_nn(self):\n",
    "\n",
    "        # Vector containing the layers that make up the network\n",
    "        self.neural_network = []\n",
    "        # Review the neural network topology and create the layers\n",
    "        for l, layer in enumerate(self.topology[:-1]):\n",
    "\n",
    "            self.neural_network.append(NeuralLayer(self.topology[l], self.topology[l+1], self.activation_function[l+1]))\n",
    "            \n",
    "    \n",
    "    def solve_unknow_dataset(self, X):\n",
    "        \n",
    "        out = [(None, X)]\n",
    "        \n",
    "        for l, layer in enumerate(self.neural_network):\n",
    "            \n",
    "            self.feedforward(l, out)\n",
    "            \n",
    "        return out[-1][1]\n",
    "    \n",
    "    \n",
    "    def train(self, backpropagation, backpropagation_type):\n",
    "        \n",
    "        out = [(None, self.dataset.X)]\n",
    "        \n",
    "        for l, layer in enumerate(self.neural_network):\n",
    "            \n",
    "            self.feedforward(l, out)\n",
    "            \n",
    "        if backpropagation:\n",
    "\n",
    "            self.backward(out, backpropagation_type)\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.normal_Wb_update(l, out)\n",
    "            \n",
    "        return out[-1][1]\n",
    "        \n",
    "    \n",
    "    def feedforward(self, l, out):\n",
    "        \n",
    "        # Weighted sum of layer[l]\n",
    "        z = out[-1][1] @ self.neural_network[l].W + self.neural_network[l].b\n",
    "\n",
    "        # Activation value of layer[l]\n",
    "        a = self.neural_network[l].activation_function[0](z)\n",
    "        \n",
    "        # Save both values of layer[l] to vector\n",
    "        out.append((z,a))\n",
    "        \n",
    "        \n",
    "    def backward(self, out, backpropagation_type):\n",
    "        \n",
    "        δ = []\n",
    "        \n",
    "        for l in reversed(range(0, len(self.neural_network))):\n",
    "            \n",
    "            z = out[l+1][0]\n",
    "            a = out[l+1][1]\n",
    "            \n",
    "            if l == len(self.neural_network)-1 :\n",
    "                \n",
    "                δ.insert(0, self.cost_function[1](a, self.dataset.Y) * self.neural_network[l].activation_function[1](z))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                δ.insert(0, δ[0] @ _W.T * self.neural_network[l].activation_function[1](z))\n",
    "                \n",
    "            _W = self.neural_network[l].W\n",
    "            \n",
    "            #GRADIENT DESCENT\n",
    "            \n",
    "            ##Primitive = 0 ; Cascade = 1\n",
    "            if backpropagation_type:\n",
    "                self.neural_network[l].b = self.neural_network[l].b - np.mean(δ[0], axis=0, keepdims=True) * self.red_config.get_learning_ratio()\n",
    "                self.neural_network[l].W = self.neural_network[l].W - out[l][1].T @ δ[0] * self.red_config.get_learning_ratio()\n",
    "            else:\n",
    "                self.neural_network[l].b = self.neural_network[l].b + np.mean(δ[0], axis=0, keepdims=True) * self.red_config.get_learning_ratio()\n",
    "                self.neural_network[l].W = self.neural_network[l].W + out[l][1].T @ δ[0] * self.red_config.get_learning_ratio()\n",
    "            \n",
    "    def normal_Wb_update(self, out):\n",
    "        \n",
    "        δ = []\n",
    "        \n",
    "        for l in range(1, len(self.neural_network)):\n",
    "            \n",
    "            z = out[l-1][0]\n",
    "            a = out[l-1][0]\n",
    "            \n",
    "            if l == len(self.neural_network)-1 :\n",
    "                \n",
    "                δ.append(self.cost_function[1](a, self.dataset.Y))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                δ.append(δ[-1] @ _W.T)\n",
    "                \n",
    "            _W = self.neural_network[l].W\n",
    "        \n",
    "            self.neural_network[l].b = self.neural_network[l].b + np.mean(δ[-1], axis=0, keepdims=True) * self.red_config.get_learning_ratio()\n",
    "        \n",
    "            self.neural_network[l].W = self.neural_network[l].W + out[l][1].T @ δ[-1] * self.red_config.get_learning_ratio()\n",
    "            \n",
    "\n",
    "    def execute(self):\n",
    "        \n",
    "        err_iterations = []\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "name 'x' is parameter and global (<ipython-input-12-ebd24a7b408a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-ebd24a7b408a>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    global x\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m name 'x' is parameter and global\n"
     ]
    }
   ],
   "source": [
    "def test(x):\n",
    "    global x\n",
    "    x = 1\n",
    "    x = x + 1\n",
    "\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
